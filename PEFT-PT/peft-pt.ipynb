{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2695ba7e-cad6-4782-926e-8aad9e4d79e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CRIA O AMBIENTE VIRTUAL\n",
    "\n",
    "conda create -n PEFT_PromptTuning python=3.11\n",
    "conda activate PEFT_PromptTuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3092ab4f-e403-464d-bf4d-85074f5e4f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSTALA AS DEPENDENCIAS\n",
    "\n",
    "pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
    "pip install tqdm ipykernel transformers==4.42.4 datasets==2.19.1 peft==0.10.0 trl==0.9.4\n",
    "# pip installaccelerate==0.30.1 tokenizers==0.19.1 bitsandbytes==0.43.1\n",
    "\n",
    "python -m ipykernel install --user --name=PEFT_PromptTuning --display-name=\"PEFT_PromptTuning\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8935f78b-71a9-42d6-953d-94735cc27f41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "area\n",
      "Direito Penal               120\n",
      "Direito Processual Civil    119\n",
      "Direito Empresarial         114\n",
      "Direito Constitucional      113\n",
      "Direito Civil               113\n",
      "Direito do Trabalho         113\n",
      "Direito do Consumidor       112\n",
      "Direito Administrativo      109\n",
      "Direito Tributário          109\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_json(\"dataset_classificacao_juridica.jsonl\", lines=True)\n",
    "print(df['area'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e48debdd-8056-43c2-b416-61410a22a4dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ricardo/.conda/envs/PEFT_PromptTuning/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# IMPORTA AS BIBLIOTECAS\n",
    "\n",
    "import torch\n",
    "from datasets import load_dataset, DatasetDict\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from peft import get_peft_model, PromptTuningConfig, TaskType, PromptTuningInit\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4263dd8-b139-4a58-8881-dc94f34c672e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIGURAÇÕES\n",
    "\n",
    "MODEL_NAME = \"Qwen/Qwen2.5-0.5B-Instruct\"\n",
    "DATASET_FILE = \"dataset_classificacao_juridica.jsonl\"\n",
    "OUTPUT_DIR = \"./modelo_juridico_prompt_tuning\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0a0536b-5b70-434e-9ec4-8ac209fb38b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapeamento de rótulos: {'Direito Processual Civil': 0, 'Direito Penal': 1, 'Direito Tributário': 2, 'Direito Civil': 3, 'Direito Administrativo': 4, 'Direito Constitucional': 5, 'Direito do Trabalho': 6, 'Direito do Consumidor': 7, 'Direito Empresarial': 8}\n",
      "\n",
      "Dataset final dividido:\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['texto', 'area', 'label'],\n",
      "        num_rows: 817\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['texto', 'area', 'label'],\n",
      "        num_rows: 102\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['texto', 'area', 'label'],\n",
      "        num_rows: 103\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# CARREGAR DATASET\n",
    "full_dataset = load_dataset('json', data_files={'train': DATASET_FILE}, split='train')\n",
    "\n",
    "# Mapeia os rótulos de texto para IDs numéricos (essencial para o modelo)\n",
    "labels = full_dataset.unique(\"area\")\n",
    "id2label = {i: label for i, label in enumerate(labels)}\n",
    "label2id = {label: i for i, label in enumerate(labels)}\n",
    "print(f\"Mapeamento de rótulos: {label2id}\")\n",
    "\n",
    "# Transforma os rótulos em IDs\n",
    "def add_labels(example):\n",
    "    example['label'] = label2id[example['area']]\n",
    "    return example\n",
    "\n",
    "full_dataset = full_dataset.map(add_labels)\n",
    "\n",
    "# Divide o dataset em treino, validação e teste\n",
    "train_test_split = full_dataset.train_test_split(test_size=0.2, shuffle=True, seed=42)\n",
    "test_validation_split = train_test_split['test'].train_test_split(test_size=0.5, shuffle=True, seed=42)\n",
    "\n",
    "final_datasets = DatasetDict({\n",
    "    'train': train_test_split['train'],\n",
    "    'validation': test_validation_split['train'],\n",
    "    'test': test_validation_split['test']\n",
    "})\n",
    "\n",
    "print(\"\\nDataset final dividido:\")\n",
    "print(final_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "277325cc-cf06-4c40-984d-7d9e33de6a84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "# TOKENIZA O TEXTO\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, trust_remote_code=True)\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    \n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"texto\"], truncation=True, padding=\"max_length\", max_length=256)\n",
    "\n",
    "tokenized_datasets = final_datasets.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7be82a21-fdea-4669-8a51-81a82b141f45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Qwen2ForSequenceClassification were not initialized from the model checkpoint at Qwen/Qwen2.5-0.5B-Instruct and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 52,864 || all params: 494,093,696 || trainable%: 0.01069918528165152\n"
     ]
    }
   ],
   "source": [
    "# CARREGAR MODELO\n",
    "\n",
    "peft_config = PromptTuningConfig(\n",
    "    task_type=TaskType.SEQ_CLS,  # Tarefa de Classificação de Sequência\n",
    "    prompt_tuning_init=PromptTuningInit.TEXT,\n",
    "    num_virtual_tokens=50,  # Tamanho do prompt virtual que será treinado\n",
    "    prompt_tuning_init_text=\"Classifique o seguinte texto jurídico na área do direito correspondente:\",\n",
    "    tokenizer_name_or_path=MODEL_NAME,\n",
    ")\n",
    "\n",
    "# Carrega o modelo base para CLASSIFICAÇÃO DE SEQUÊNCIA\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=len(labels), # Informa ao modelo quantas classes existem\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    "    trust_remote_code=True,\n",
    "    # device_map=\"auto\" # Usar se tiver VRAM suficiente\n",
    ")\n",
    "\n",
    "model.config.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "# Adiciona o adaptador de Prompt Tuning ao modelo\n",
    "model = get_peft_model(model, peft_config)\n",
    "\n",
    "# Imprime os parâmetros treináveis (será um número pequeno)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed7dbf83-b786-4eed-88da-778545933eda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1545' max='1545' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1545/1545 04:32, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>2.168771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>2.392521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>2.148149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>2.069149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.728600</td>\n",
       "      <td>2.211992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.728600</td>\n",
       "      <td>1.942071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.728600</td>\n",
       "      <td>1.815562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.728600</td>\n",
       "      <td>1.763541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.728600</td>\n",
       "      <td>1.723557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.130700</td>\n",
       "      <td>1.552305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1.130700</td>\n",
       "      <td>1.562266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1.130700</td>\n",
       "      <td>1.555993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1.130700</td>\n",
       "      <td>1.640425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1.130700</td>\n",
       "      <td>1.604594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.608200</td>\n",
       "      <td>1.590710</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treinamento concluído. Salvando o adaptador em: ./modelo_juridico_prompt_tuning\n"
     ]
    }
   ],
   "source": [
    "# EXECUTA O TREINAMENTO\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    learning_rate=2e-4, # Prompt Tuning geralmente usa uma taxa de aprendizado maior que LoRA\n",
    "    num_train_epochs=12,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    weight_decay=0.01,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=False,\n",
    "    overwrite_output_dir=True,\n",
    "    report_to=\"none\",\n",
    "    lr_scheduler_type='cosine',\n",
    "    warmup_steps=100,\n",
    ")\n",
    "\n",
    "# Instanciar o Trainer padrão\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "print(f\"Treinamento concluído. Salvando o adaptador em: {OUTPUT_DIR}\")\n",
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fae73dd9-f7a4-4bfb-884f-fd5a43212787",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Qwen2ForSequenceClassification were not initialized from the model checkpoint at Qwen/Qwen2.5-0.5B-Instruct and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Teste de Inferência Manual ---\n",
      "Texto: 'O réu foi condenado por homicídio qualificado, com pena base acima do mínimo legal.'\n",
      "Resultado da Classificação: {'label': 'Direito Processual Civil', 'score': 0.9767060875892639}\n",
      "\n",
      "Texto: 'A empresa foi autuada por não recolher o PIS e a COFINS sobre o faturamento.'\n",
      "Resultado da Classificação: {'label': 'Direito Processual Civil', 'score': 0.8986489176750183}\n"
     ]
    }
   ],
   "source": [
    "# VERIFICAÇÃO E DEMONSTRAÇÃO\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from peft import PeftModel\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "base_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=len(labels),\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "model_com_prompt = PeftModel.from_pretrained(base_model, OUTPUT_DIR)\n",
    "\n",
    "# Carrega o tokenizador\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, trust_remote_code=True)\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    model_com_prompt.config.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "# Garante que o modelo esteja em modo de avaliação (desativa dropout, etc.)\n",
    "model_com_prompt.eval()\n",
    "\n",
    "# Move o modelo para a GPU, se disponível\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_com_prompt.to(device)\n",
    "\n",
    "\n",
    "def classificar_texto(texto):\n",
    "    # Tokeniza a entrada, convertendo para tensores PyTorch e movendo para a GPU\n",
    "    inputs = tokenizer(texto, return_tensors=\"pt\", truncation=True, padding=True).to(device)\n",
    "\n",
    "    # Faz a predição sem calcular gradientes (mais rápido e economiza memória)\n",
    "    with torch.no_grad():\n",
    "        outputs = model_com_prompt(**inputs)\n",
    "\n",
    "    # A saída do modelo são 'logits' (valores brutos)\n",
    "    logits = outputs.logits\n",
    "\n",
    "    # Aplica a função softmax para converter logits em probabilidades\n",
    "    probabilities = F.softmax(logits, dim=-1)\n",
    "\n",
    "    # Pega o índice da classe com a maior probabilidade\n",
    "    predicted_class_id = torch.argmax(probabilities, dim=-1).item()\n",
    "\n",
    "    # Usa o mapeamento id2label para obter o nome da classe\n",
    "    predicted_class_label = model_com_prompt.config.id2label[predicted_class_id]\n",
    "    \n",
    "    # Pega a probabilidade da classe prevista\n",
    "    confidence_score = probabilities[0][predicted_class_id].item()\n",
    "\n",
    "    return {\"label\": predicted_class_label, \"score\": confidence_score}\n",
    "\n",
    "\n",
    "texto_exemplo = \"O réu foi condenado por homicídio qualificado, com pena base acima do mínimo legal.\"\n",
    "resultado = classificar_texto(texto_exemplo)\n",
    "\n",
    "print(\"\\n--- Teste de Inferência Manual ---\")\n",
    "print(f\"Texto: '{texto_exemplo}'\")\n",
    "print(f\"Resultado da Classificação: {resultado}\")\n",
    "\n",
    "texto_exemplo_2 = \"A empresa foi autuada por não recolher o PIS e a COFINS sobre o faturamento.\"\n",
    "resultado_2 = classificar_texto(texto_exemplo_2)\n",
    "print(f\"\\nTexto: '{texto_exemplo_2}'\")\n",
    "print(f\"Resultado da Classificação: {resultado_2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4660ef12-7205-45fc-b62e-ecc4204fc339",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PEFT_PromptTuning",
   "language": "python",
   "name": "peft_prompttuning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
