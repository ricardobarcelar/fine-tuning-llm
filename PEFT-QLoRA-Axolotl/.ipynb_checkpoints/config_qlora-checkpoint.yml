# 1. Modelo Base
base_model: Qwen/Qwen2.5-0.5B-Instruct
model_type: AutoModelForCausalLM
trust_remote_code: true
tokenizer_type: AutoTokenizer

# 2. Configuração de Quantização e Precisão
load_in_4bit: true
bf16: true
fp16: false

# 3. Dataset e Formato do Prompt
datasets:
  - path: dataset_instrucoes_juridico.jsonl  
    type: alpaca
    # Mapeamento das suas colunas para o formato Alpaca:
    field_instruction: titulo 
    field_output: conteudo
    # Se tivéssemos uma coluna de 'input' adicional, usaríamos 'field_input'.

# 4. Hiperparâmetros do Treinamento
output_dir: ./outputs/modelo_juridico_axolotl_lora
sequence_len: 1024
sample_packing: true # Empacota exemplos curtos em uma única sequência para acelerar o treino
num_train_epochs: 5
micro_batch_size: 2
gradient_accumulation_steps: 8
learning_rate: 5e-5
lr_scheduler_type: cosine
warmup_steps: 100
weight_decay: 0.01

# 5. Configuração de Avaliação e Logs
val_set_size: 0.1 # 10% do dataset para validação.
eval_strategy: steps
eval_steps: 100
save_strategy: steps
save_steps: 100
logging_steps: 10

# 6. Configuração da Técnica PEFT (LoRA)
adapter: lora
lora_r: 16
lora_alpha: 32
lora_dropout: 0.1
lora_target_modules:
  - q_proj
  - k_proj
  - v_proj
  - o_proj
  - gate_proj
  - up_proj
  - down_proj